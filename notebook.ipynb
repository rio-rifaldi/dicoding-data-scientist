{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyek Analisis Data: E-Commerce Public Dataset \n",
    "\n",
    "- **Nama:** RIO RIFALDI\n",
    "- **Email:** riorifaldi0604@gmail.com\n",
    "- **ID Dicoding:** riorifaldi0604\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menentukan Pertanyaan Bisnis\n",
    "\n",
    "- produk kategori apa yang memiliki harga paling tinggi dan terendah?\n",
    "- tipe pembayaran apa yang paling diminati pelanggan?\n",
    "- produk kategori apa yang jarang dan sering tersedia oleh pelaku usaha?\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Semua Packages/Library yang Digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "customers_df = pd.read_csv(\"https://gist.githubusercontent.com/rio-rifaldi/155e2af867a2c850a5592be09fee6081/raw/f1710f507b9bdc15b0236ae0bf3568364e4f6193/customers_dataset.csv\")\n",
    "geolocation_df = pd.read_csv(\"https://drive.usercontent.google.com/download?id={}&export=download&authuser=0&confirm=t'.format('https://drive.google.com/file/d/1FHSCpaSKSHb72Z3ie18AhSZDkFnzBV_-/view?usp=drive_link'.split('/')[-2])\")\n",
    "order_items_df = pd.read_csv(\"https://gist.githubusercontent.com/rio-rifaldi/c57de62d81a503703ad9669ce8c1dc08/raw/06acbda7b427965cf21b9e7b59b013bef42085da/order_items_dataset.csv\")\n",
    "order_payments_df = pd.read_csv(\"https://gist.githubusercontent.com/rio-rifaldi/51927cf6ca9a2a251001a637be603150/raw/79f00245f25718e30b05cb8a642f1d1eeaf413b7/order_payments_dataset.csv\")\n",
    "order_reviews_df = pd.read_csv(\"https://gist.githubusercontent.com/rio-rifaldi/b96d44aeef814c4642bf15b1f28eeb70/raw/701f2aad5bc647932ea82d265b2d71913eae117a/order_reviews_dataset.csv\")\n",
    "orders_df = pd.read_csv(\"https://gist.githubusercontent.com/rio-rifaldi/e31bf6c489bb85bbb438aff041969bc9/raw/38f99c7bd2c536fae897c67d66142f7bdaf09aa2/orders_dataset.csv\")\n",
    "product_category_df = pd.read_csv(\"https://gist.githubusercontent.com/rio-rifaldi/f037933fb0c387e6e53125ebdb9d3792/raw/f3cf6b1512881a4e28e326f229f097d69604e4d7/product_category_name_translation.csv\")\n",
    "products_df = pd.read_csv(\"https://gist.githubusercontent.com/rio-rifaldi/db3813432a4ad248555f5cefe71bd047/raw/59508020fa8c8964c340efbb491bbc45cf3719d5/products_dataset.csv\")\n",
    "sellers_df = pd.read_csv(\"https://gist.githubusercontent.com/rio-rifaldi/c50e345a35161ccb40601663a1a090d0/raw/10678fcef2ecda25437f24d319d0927cc2a09c00/sellers_dataset.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:**\n",
    "- memasukkan data CSV dengan menggunakan library pandas\n",
    "- saya menggunakan function `read_csv()` dan memasukkannya ke dalam masing masing variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data customers\n",
    "print(\"duplication customers_df : \", customers_df.duplicated().sum())\n",
    "print()\n",
    "customers_df.info()\n",
    "customers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data geolocation\n",
    "print(\"duplication geolocation_df : \", geolocation_df.duplicated().sum())\n",
    "print()\n",
    "geolocation_df.info()\n",
    "geolocation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data order_items\n",
    "print(\"duplication order_items_df : \", order_items_df.duplicated().sum())\n",
    "print()\n",
    "\n",
    "order_items_df.info()\n",
    "order_items_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data order_payment\n",
    "\n",
    "print(\"duplication order_payments_df : \", order_payments_df.duplicated().sum())\n",
    "print()\n",
    "order_payments_df.info()\n",
    "order_payments_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data order_reviews\n",
    "\n",
    "print(\"duplication order_reviews_df : \", order_reviews_df.duplicated().sum())\n",
    "print()\n",
    "order_reviews_df.info()\n",
    "order_reviews_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check order_dataset\n",
    "print(\"duplication order_df : \", orders_df.duplicated().sum())\n",
    "print()\n",
    "\n",
    "orders_df.info()\n",
    "orders_df.isna().sum()\n",
    "orders_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product category check\n",
    "print(\"duplication product_category_df : \", product_category_df.duplicated().sum())\n",
    "print()\n",
    "\n",
    "product_category_df.info()\n",
    "product_category_df.isna().sum()\n",
    "product_category_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product dataset check\n",
    "\n",
    "print(\"duplication products_df : \", products_df.duplicated().sum())\n",
    "print()\n",
    "\n",
    "products_df.info()\n",
    "products_df.isna().sum()\n",
    "products_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seller dataset check\n",
    "\n",
    "print(\"duplication sellers_df : \", sellers_df.duplicated().sum())\n",
    "print()\n",
    "\n",
    "sellers_df.info()\n",
    "sellers_df.isna().sum()\n",
    "sellers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insight:\n",
    "1. check dataframe `customers_df` apakah ada duplikasi atau kesalahan tipe data, ternyata tidak ada semuanya normal\n",
    "2. check dataframe `geolocation_df` apakah ada duplikasi atau kesalahan tipe data, ternyata terdeteksi duplikasi data sebanyak 261831; namun tidak ada kesalahan tipe data\n",
    "3. check dataframe `order_items_df` apakah ada duplikasi atau kesalahan tipe data, ternyata tidak ada duplikasi namun terdapat kesalahan tipe data pada kolom *shipping_limit_date*\n",
    "4. check dataframe `order_payments_df` apakah ada duplikasi, kesalahan tipe data dan data yang bias. ternyata tidak ada semuanya normal\n",
    "5. check dataframe `order_reviews_df` apakah ada duplikasi, kesalahan tipe data dan data yang bias. tidak ada duplikasi, namun terdapat beberapa data yang masih kosong dan tipe data yang tidak sesuai pada kolom *review_creation_date* dan *review_answer_timestamp*\n",
    "6.  check dataframe `orders_df` apakah ada duplikasi, kesalahan tipe data dan data yang bias. tidak ada duplikasi, namun terdapat beberapa data yang masih kosong dan tipe data yang tidak sesuai pada kolom *order_purchase_timestamp*, *order_approved_at*,  *order_delivered_carrier_date*,  *order_delivered_customer_date*  dan *order_estimated_delivery_date*\n",
    "7.  check dataframe `product_category_df` apakah ada duplikasi, kesalahan tipe data dan data yang bias. ternyata tidak ada semuanya normal\n",
    "8.  check dataframe `products_df` apakah ada duplikasi, kesalahan tipe data dan data yang bias. ternyata tidak ada duplikasi namun terdapat beberapa data yang masih kosong\n",
    "9.  check dataframe `sellers_df` apakah ada duplikasi, kesalahan tipe data dan data yang bias. ternyata tidak ada semuanya normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data geolocatiom_df\n",
    "geolocation_df.drop_duplicates(inplace=True)\n",
    "print(\"duplication geolocation_df  after cleaning : \", geolocation_df.duplicated().sum())\n",
    "geolocation_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype of shipping_limit_date to datetime\n",
    "order_items_df[\"shipping_limit_date\"] = pd.to_datetime(order_items_df[\"shipping_limit_date\"])\n",
    "order_items_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing value on review_comment_title with dominant value\n",
    "order_reviews_df.review_comment_title.value_counts()\n",
    "order_reviews_df.review_comment_title.fillna(value=\"Recomendo\",inplace=True)\n",
    "\n",
    "# replace missing value on review_comment_message with dominant value\n",
    "order_reviews_df.review_comment_message.fillna(value=\"Muito bom\",inplace=True)\n",
    "order_reviews_df.review_comment_message.value_counts()\n",
    "\n",
    "# change review_answer_timestamp and review_creation_date data type to date\n",
    "datetime_column = [\"review_answer_timestamp\",\"review_creation_date\"]\n",
    "\n",
    "for column in datetime_column:\n",
    "    order_reviews_df[column] = pd.to_datetime(order_reviews_df[column])\n",
    "\n",
    "order_reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change order_df wrong datatype\n",
    "date_column = [\n",
    "\"order_purchase_timestamp\",     \n",
    "\"order_approved_at\",            \n",
    "\"order_delivered_carrier_date\", \n",
    "\"order_delivered_customer_date\",\n",
    "\"order_estimated_delivery_date\"\n",
    "]\n",
    "for column in date_column:\n",
    "    orders_df[column] = pd.to_datetime(orders_df[column])\n",
    "\n",
    "orders_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set uncategories product with \"others\" category\n",
    "new_category = {\"product_category_name\" : \"others\",\"product_category_name_english\" : \"others\"}\n",
    "\n",
    "product_category_df.loc[len(product_category_df)] = new_category;\n",
    "product_category_df.reset_index(drop=True)\n",
    "\n",
    "product_category_df.drop_duplicates(inplace=True)\n",
    "\n",
    "product_category_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop two data with almost null value at whole column\n",
    "products_df.drop(products_df[products_df[\"product_width_cm\"].isna()].index,inplace=True)\n",
    "\n",
    "# fill other uncategories data with category \"others\"\n",
    "products_df[\"product_category_name\"].fillna(value=\"others\",inplace=True)\n",
    "\n",
    "# fill product_name_lenght with average of all data\n",
    "average_product_name = math.floor(products_df.product_name_lenght.mean())\n",
    "products_df[\"product_name_lenght\"].fillna(value=average_product_name,inplace=True)\n",
    "\n",
    "# fill  product_description_lenght with average of all data\n",
    "average_product_description = math.floor(products_df.product_description_lenght.mean())\n",
    "products_df[\"product_description_lenght\"].fillna(value=average_product_description,inplace=True)\n",
    "\n",
    "\n",
    "# fill product_photos_qty with average of all data\n",
    "average_product_photo_qty = math.floor(products_df.product_photos_qty.mean())\n",
    "products_df[\"product_photos_qty\"].fillna(value=average_product_photo_qty,inplace=True)\n",
    "\n",
    "\n",
    "products_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insight:\n",
    "- pertama saya melakukan pembersihan data duplikasi pada dataframe geolocation dengan menggunakan funsi `geolocation_df.drop_duplicates(inplace=True)`\n",
    "- pada `order_items_df`, saya melakikan pengubahan tipe data yang tidak sesuai, yaitu tipe data object menjadi datetime menggunakan fungsi dari pandas `pd.to_datetime()`\n",
    "- pada `order_reviews_df` saya akan melakukan pengisian data yang kosong dengan mempertimbangkan data yang paling dominan. selain itu saya juga melakukan konversi tipe data menjadi datetime pada kolom review_answer_timestamp dan review_creation_date\n",
    "- pada `orders_df` saya juga melakukan konversi tipe data menjadi datetime, kolom tersebut diantaranta ialah order_purchase_timestamp, order_approved_at,  order_delivered_carrier_date, order_delivered_customer_date dan order_estimated_delivery_date  \n",
    "- pada `product_category_df` saya menambahkan kategori baru yaitu *others*, hal ini saya lakukan karena terdapat beberapa produk yang tidak terkategori dan dianggap sebagai data yang kosong\n",
    "- pada `products_df` saya melakukan pengisian data yang kosong berdasarkan rata rata dari seluruh data, selain itu saya juga mengisikan produk yang tidak terkategori menjadi *others*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization & Explanatory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_payments_df.groupby(by=\"payment_type\").agg({\n",
    "    \"payment_value\" : [\"mean\",\"min\",\"std\"]\n",
    "})\n",
    "\n",
    "sellers_product_df = order_items_df[[\"seller_id\",\"product_id\",\"price\",\"freight_value\"]].merge(products_df[[\"product_id\",\"product_category_name\"]],how=\"left\").merge(sellers_df,how=\"left\").merge(products_df[[\"product_weight_g\",\"product_id\",\"product_length_cm\",\"product_height_cm\",\"product_width_cm\"]],how=\"left\").merge(product_category_df,how=\"left\")\n",
    "\n",
    "sellers_product_df.groupby(\"product_category_name\").seller_id.nunique().sort_values(ascending=False)\n",
    "\n",
    "sellers_product_df.groupby(\"product_category_name\").agg({\n",
    "    \"product_id\" :\"nunique\",\n",
    "    \"price\":[\"max\",\"min\",\"mean\"]\n",
    "})\n",
    "\n",
    "sellers_product_df.groupby([\"product_category_name\",\"seller_state\"]).seller_id.nunique().sort_values(ascending=False).head(10)\n",
    "\n",
    "sellers_product_df.groupby([\"product_category_name\",\"seller_state\"]).product_id.nunique().sort_values(ascending=False).head(10)\n",
    "\n",
    "products_df.groupby([\"product_category_name\",\"product_weight_g\"]).product_id.nunique().sort_values(ascending=False)\n",
    "\n",
    "sellers_product_df[\"volume_in_cm\"] = (sellers_product_df[\"product_length_cm\"] * sellers_product_df[\"product_height_cm\"] * sellers_product_df[\"product_width_cm\"])\n",
    "\n",
    "\n",
    "sellers_product_df.drop(columns=[\"product_category_name\"],inplace=True)\n",
    "sellers_product_df.rename(columns={\"product_category_name_english\" : \"product_category_name\"},inplace=True)\n",
    "\n",
    "sellers_product_df.groupby([\"product_category_name\",\"volume_in_cm\"]).product_id.nunique().sort_index(ascending=False)\n",
    "\n",
    "\n",
    "def quote_text_only(value):\n",
    "    if isinstance(value, str):  \n",
    "        return f'\"{value}\"'\n",
    "    else:\n",
    "        return value  \n",
    "\n",
    "\n",
    "df_quoted = sellers_product_df.applymap(quote_text_only)\n",
    "df_quoted.to_csv('./dashboard/main_data.csv', index=False, quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "\n",
    "sellers_product_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pertanyaan 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "product_price = sellers_product_df.groupby([\"product_category_name\",\"price\"]).product_id.nunique().sort_index(ascending=False).reset_index()\n",
    "\n",
    "\n",
    "product_price.drop(columns=\"product_id\",inplace=True)\n",
    "product_price.columns = [\"product_category_name\",\"mean_price\"]\n",
    "\n",
    "product_mean_price = product_price.groupby(\"product_category_name\").mean().mean_price.to_dict()\n",
    "\n",
    "\n",
    "categories = list(product_mean_price.keys())\n",
    "values = list(product_mean_price.values())\n",
    "data = pd.DataFrame({'Category': categories, 'Value': values}).sort_values(by='Value', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 28))  \n",
    "plt.barh(data['Category'], data['Value'], color='skyblue')\n",
    "plt.xlabel('Price in $')\n",
    "plt.title('Product Categories Mean Price')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pertanyaan 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "customer_payment_list = order_payments_df.groupby([\"payment_type\"]).order_id.nunique().sort_values(ascending=False)\n",
    "\n",
    "customer_payment_list_dict = customer_payment_list.to_dict()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "payment_method = list(customer_payment_list_dict.keys())\n",
    "data_payment_method = list(customer_payment_list_dict.values())\n",
    "bar_colors = ['tab:green', 'tab:blue', 'tab:red', 'tab:orange','tab:blue']\n",
    "\n",
    "ax.bar(payment_method, data_payment_method, color=bar_colors)\n",
    "\n",
    "ax.set_ylabel('Customer Count')\n",
    "ax.set_title('Most Popular Payment Types')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pertanyaan 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_list_dict = sellers_product_df.groupby([\"product_category_name\"]).product_id.nunique().sort_values(ascending=False).head(10).to_dict()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "data_product_categories = list(data_list_dict.keys())\n",
    "data_product_values = list(data_list_dict.values())\n",
    "y_pos = np.arange(len(data_product_categories))\n",
    "error = np.random.rand(len(data_product_categories))\n",
    "\n",
    "ax.barh(y_pos, data_product_values, xerr=error, align='center')\n",
    "ax.set_yticks(y_pos, labels=data_product_categories)\n",
    "ax.invert_yaxis()  \n",
    "ax.set_xlabel('Product Stock')\n",
    "ax.set_title('High Product Product Stock Categories')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis Lanjutan (Opsional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclution pertanyaan 1\n",
    "dari data diatas dapat kita simpulkan bahwa produk kategori dengan nilai termahal adalah *computers* dan produk termurah adalah *flowes*\n",
    "    \n",
    "#### Conclution pertanyaan 2\n",
    "hasil analisis menunjukkan customer cenderung memilih metode pembayaran dengan kartu kredit hingga 76795, ini sangatlah logis karena kemudahan pembayaran dengan hanya menggesek kartu membuat pengalaman yang bagus untuk customers\n",
    "\n",
    "#### Conclution pertanyaan 3\n",
    "hasil analisis menunjukkan bahwa produk kategori dengan stok terbanyak adalah  *bed_bath_table* dan produk dengan stok terbanyak ke 10 adalah *telephony*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
